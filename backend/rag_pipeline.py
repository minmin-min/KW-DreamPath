import os
import json
import psycopg2
import numpy as np
from openai import OpenAI
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from dotenv import load_dotenv

# ===== .env ë¶ˆëŸ¬ì˜¤ê¸° =====
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ===== ê¸°ë³¸ ì„¤ì • =====
OPENAI_MODEL = "gpt-3.5-turbo"  # í•„ìš” ì‹œ gpt-4o ë“±ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥
PG_DSN = {
    "host": "localhost",
    "dbname": "KWchatbot",  # âœ… DB ì´ë¦„
    "user": "postgres",
    "password": "130802",  # âœ… ë¹„ë°€ë²ˆí˜¸
}
SIM_THRESHOLD = 0.25  # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì„ê³„ê°’ (ë‚®ì„ìˆ˜ë¡ ë” ë§ì€ ê²°ê³¼ í—ˆìš©)

# ===== SentenceTransformer (ê³µê°œ í•œêµ­ì–´ SBERT ëª¨ë¸) =====
MODEL_PATH = "jhgan/ko-sbert-sts"
model = SentenceTransformer(MODEL_PATH)

# ===== OpenAI í´ë¼ì´ì–¸íŠ¸ =====
client = OpenAI(api_key=OPENAI_API_KEY)


# ==========================================
# ğŸ”¹ Postgresì—ì„œ top-3 ìœ ì‚¬ ì²­í¬ ê°€ì ¸ì˜¤ê¸°
# ==========================================
def _fetch_top3_chunks(query_embedding, categories=None):
    conn = psycopg2.connect(**PG_DSN)
    cur = conn.cursor()

    # âœ… ì¹´í…Œê³ ë¦¬ í•„í„°ë§
    if categories:
        cur.execute(
            """
            SELECT dc.chunk_text, dc.chunk_metadata
            FROM embeddings e
            JOIN doc_chunks dc ON e.chunk_id = dc.chunk_id
            WHERE dc.chunk_metadata->>'ì¹´í…Œê³ ë¦¬' = ANY(%s)
            ORDER BY e.embedding <#> %s::vector
            LIMIT 3
            """,
            (categories, query_embedding),
        )
    else:
        cur.execute(
            """
            SELECT dc.chunk_text, dc.chunk_metadata
            FROM embeddings e
            JOIN doc_chunks dc ON e.chunk_id = dc.chunk_id
            WHERE dc.chunk_metadata->>'ì¹´í…Œê³ ë¦¬' != 'ê³µì§€ì‚¬í•­'
            ORDER BY e.embedding <#> %s::vector
            LIMIT 3
            """,
            (query_embedding,),
        )

    rows = cur.fetchall()

    # âœ… [ì¶”ê°€] ê²€ìƒ‰ëœ ì²­í¬ë¥¼ í„°ë¯¸ë„ì— ì¶œë ¥
    print("\n========== ğŸ” ê²€ìƒ‰ëœ Top-3 ì²­í¬ ==========")
    if not rows:
        print("âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        for i, (text, meta) in enumerate(rows, 1):
            category_name = (
                meta.get("ì¹´í…Œê³ ë¦¬", "ì—†ìŒ") if isinstance(meta, dict) else "ì—†ìŒ"
            )
            preview = text[:200].replace("\n", " ")  # ì¤„ë°”ê¿ˆ ì œê±° + ì¼ë¶€ë§Œ ì¶œë ¥
            print(f"[{i}] ì¹´í…Œê³ ë¦¬: {category_name}")
            print(f"ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°: {preview}...\n")
    print("=========================================\n")

    cur.close()
    conn.close()
    return rows


# ==========================================
# ğŸ”¹ í•µì‹¬: RAG ë‹µë³€ ìƒì„± í•¨ìˆ˜
# ==========================================
def generate_answer(user_query, category=None):
    # 1ï¸âƒ£ ê³µì§€ì‚¬í•­ ìš”ì²­ ì²˜ë¦¬
    if category == ["ê³µì§€ì‚¬í•­"]:
        conn = psycopg2.connect(**PG_DSN)
        cur = conn.cursor()
        cur.execute(
            """
            SELECT 
                chunk_metadata->'ê¸°íƒ€'->>'ì œëª©' AS ì œëª©,
                chunk_metadata->'ê¸°íƒ€'->>'ì‘ì„±ì¼' AS ì‘ì„±ì¼,
                chunk_metadata->'ê¸°íƒ€'->>'ì²¨ë¶€íŒŒì¼' AS url
            FROM doc_chunks
            WHERE category = 'ê³µì§€ì‚¬í•­'
              AND chunk_index = 0
            ORDER BY (chunk_metadata->'ê¸°íƒ€'->>'ì‘ì„±ì¼')::date DESC
            LIMIT 5
            """
        )
        rows = cur.fetchall()
        cur.close()
        conn.close()

        if rows:
            notices = []
            for ì œëª©, ì‘ì„±ì¼, url in rows:
                notices.append({"ì œëª©": ì œëª©, "ì‘ì„±ì¼": ì‘ì„±ì¼, "url": url or "#"})
            return notices
        else:
            return []

    # 2ï¸âƒ£ ì‚¬ìš©ì ì§ˆë¬¸ ì„ë² ë”© ìƒì„±
    query_embedding = model.encode(user_query).tolist()

    # 3ï¸âƒ£ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë°›ì€ ì¹´í…Œê³ ë¦¬ ì´ë¦„ ì •ë¦¬
    selected_category = None
    if category and isinstance(category, list):
        selected_category = category[0]

    # âœ… 4ï¸âƒ£ ë²„íŠ¼ ì´ë¦„ â†’ DB ì¹´í…Œê³ ë¦¬ ë§¤í•‘
    category_map = {
        "ê°•ì˜": ["ê°•ì˜ì •ë³´", "í•™ê³¼ì •ë³´"],
        "ë™ì•„ë¦¬": ["ë™ì•„ë¦¬"],
        "ì·¨ì—… ì •ë³´": ["ì·¨ì—…"],
    }
    db_categories = category_map.get(selected_category, None)

    # 5ï¸âƒ£ DBì—ì„œ ìœ ì‚¬í•œ ì²­í¬ top-3 ê²€ìƒ‰
    rows = _fetch_top3_chunks(query_embedding, categories=db_categories)

    # 6ï¸âƒ£ ìœ ì‚¬ë„ ì„ê³„ê°’ ê²€ì‚¬
    if not rows:
        return "â— ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    top_texts = [t for (t, _m) in rows]
    qvec = np.array(query_embedding).reshape(1, -1)
    cvecs = model.encode(top_texts)
    sims = cosine_similarity(qvec, cvecs)[0]

    if float(np.max(sims)) < SIM_THRESHOLD:
        return "â— í•´ë‹¹ ì£¼ì œì™€ ìœ ì‚¬í•œ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    # 7ï¸âƒ£ ë¬¸ë§¥(context) êµ¬ì„±
    context_items = []
    for i, (text, meta) in enumerate(rows, 1):
        meta_str = (
            json.dumps(meta, ensure_ascii=False) if not isinstance(meta, str) else meta
        )
        context_items.append(f"-----\në³¸ë¬¸:\n{text}\në©”íƒ€ë°ì´í„°:\n{meta_str}")
    context = "\n".join(context_items)

    # 8ï¸âƒ£ LLM í˜¸ì¶œ
    system = """
    ë‹¹ì‹ ì€ ê´‘ìš´ëŒ€í•™êµ KW Chatbotì…ë‹ˆë‹¤.
    ë‹¹ì‹ ì´ ë³´ê³  ë‹µí•˜ëŠ” ì²­í¬ 3ê°œë¥¼ ì‚¬ìš©ìì—ê²Œ ì•Œë ¤ì£¼ì„¸ìš”. ì •í™•í•˜ì§€ ì•Šì•„ë„ ìƒê´€ ì—†ìŠµë‹ˆë‹¤.
    ì•„ë˜ CONTEXTì˜ ì •ë³´ë§Œì„ ê·¼ê±°ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•íˆ ë‹µí•˜ì„¸ìš”.
    CONTEXTì— ì—†ëŠ” ì •ë³´ëŠ” "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."ë¼ê³  ë‹µí•˜ì„¸ìš”.
    """
    user = f"{context}\n\nì§ˆë¬¸: {user_query}\n\nì •ë‹µ:"

    try:
        resp = client.chat.completions.create(
            model=OPENAI_MODEL,
            temperature=0.0,
            messages=[
                {"role": "system", "content": system},
                {"role": "user", "content": user},
            ],
        )
        return resp.choices[0].message.content

    except Exception as e:
        return f"â— GPT ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
