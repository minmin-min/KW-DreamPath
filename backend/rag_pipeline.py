# rag_pipeline.py
import os
import json
import psycopg2
import numpy as np
from openai import OpenAI
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from dotenv import load_dotenv

# ===== .env ë¶ˆëŸ¬ì˜¤ê¸° =====
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ===== ê¸°ë³¸ ì„¤ì • =====
OPENAI_MODEL = "gpt-3.5-turbo"  # í•„ìš” ì‹œ gpt-4o ë“±ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥
PG_DSN = {
    "host": "localhost",
    "dbname": "KWchatbot",  # âœ… ë„ˆí¬ DB ì´ë¦„
    "user": "postgres",
    "password": "130802",  # âœ… ë„ˆ ë¹„ë°€ë²ˆí˜¸
}
SIM_THRESHOLD = 0.25  # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì„ê³„ê°’ (ë‚®ì„ìˆ˜ë¡ ë” ë§ì€ ê²°ê³¼ í—ˆìš©)

# ===== SentenceTransformer (ê³µê°œ í•œêµ­ì–´ SBERT ëª¨ë¸) =====
MODEL_PATH = "jhgan/ko-sbert-sts"
model = SentenceTransformer(MODEL_PATH)

# ===== OpenAI í´ë¼ì´ì–¸íŠ¸ =====
client = OpenAI(api_key=OPENAI_API_KEY)


# ==========================================
# ğŸ”¹ Postgresì—ì„œ top-3 ìœ ì‚¬ ì²­í¬ ê°€ì ¸ì˜¤ê¸°
# ==========================================
def _fetch_top3_chunks(query_embedding):
    conn = psycopg2.connect(**PG_DSN)
    cur = conn.cursor()
    cur.execute(
        """
        SELECT dc.chunk_text, dc.chunk_metadata
        FROM embeddings e
        JOIN doc_chunks dc ON e.chunk_id = dc.chunk_id
        WHERE dc.chunk_metadata->>'ì¹´í…Œê³ ë¦¬' != 'ê³µì§€ì‚¬í•­'
        ORDER BY e.embedding <#> %s::vector
        LIMIT 3
        """,
        (query_embedding,),
    )
    rows = cur.fetchall()
    cur.close()
    conn.close()
    return rows


# ==========================================
# ğŸ”¹ í•µì‹¬: RAG ë‹µë³€ ìƒì„± í•¨ìˆ˜
# ==========================================
def generate_answer(user_query, category=None):
    # 1) ê³µì§€ì‚¬í•­ ìš”ì²­ ì²˜ë¦¬
    if category == ["ê³µì§€ì‚¬í•­"]:
        conn = psycopg2.connect(**PG_DSN)
        cur = conn.cursor()

        cur.execute(
            """
            SELECT 
                chunk_metadata->'ê¸°íƒ€'->>'ì œëª©' AS ì œëª©,
                chunk_metadata->'ê¸°íƒ€'->>'ì‘ì„±ì¼' AS ì‘ì„±ì¼,
                chunk_metadata->'ê¸°íƒ€'->>'ì²¨ë¶€íŒŒì¼' AS url
            FROM doc_chunks
            WHERE category = 'ê³µì§€ì‚¬í•­'
              AND chunk_index = 0
            ORDER BY (chunk_metadata->'ê¸°íƒ€'->>'ì‘ì„±ì¼')::date DESC
            LIMIT 5
            """
        )

        rows = cur.fetchall()
        cur.close()
        conn.close()

        if rows:
            notices = []
            for ì œëª©, ì‘ì„±ì¼, url in rows:
                notices.append({"ì œëª©": ì œëª©, "ì‘ì„±ì¼": ì‘ì„±ì¼, "url": url or "#"})
            return notices
        else:
            return []

    # 2) ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
    query_embedding = model.encode(user_query).tolist()

    # 3) DBì—ì„œ ìœ ì‚¬í•œ ì²­í¬ top-3 ê°€ì ¸ì˜¤ê¸°
    rows = _fetch_top3_chunks(query_embedding)

    # 4) ìœ ì‚¬ë„ ì„ê³„ê°’ ê²€ì‚¬
    if not rows:
        return "â— ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
    top_texts = [t for (t, _m) in rows]
    qvec = np.array(query_embedding).reshape(1, -1)
    cvecs = model.encode(top_texts)
    sims = cosine_similarity(qvec, cvecs)[0]
    if float(np.max(sims)) < SIM_THRESHOLD:
        return "â— í•´ë‹¹ ì£¼ì œì™€ ìœ ì‚¬í•œ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    # 5) ë¬¸ë§¥(context) êµ¬ì„±
    context_items = []
    for i, (text, meta) in enumerate(rows, 1):
        meta_str = (
            json.dumps(meta, ensure_ascii=False) if not isinstance(meta, str) else meta
        )
        context_items.append(f"-----\në³¸ë¬¸:\n{text}\në©”íƒ€ë°ì´í„°:\n{meta_str}")
    context = "\n".join(context_items)

    # 6) LLM í˜¸ì¶œ
    system = """
    ë‹¹ì‹ ì€ ê´‘ìš´ëŒ€í•™êµ KW Chatbotì…ë‹ˆë‹¤.
    ì•„ë˜ CONTEXTì˜ ì •ë³´ë§Œì„ ê·¼ê±°ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•íˆ ë‹µí•˜ì„¸ìš”.
    CONTEXTì— ì—†ëŠ” ì •ë³´ëŠ” "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."ë¼ê³  ë‹µí•˜ì„¸ìš”.
    """
    user = f"{context}\n\nì§ˆë¬¸: {user_query}\n\nì •ë‹µ:"

    try:
        resp = client.chat.completions.create(
            model=OPENAI_MODEL,
            temperature=0.0,
            messages=[
                {"role": "system", "content": system},
                {"role": "user", "content": user},
            ],
        )
        return resp.choices[0].message.content
    except Exception as e:
        return f"â— GPT ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
