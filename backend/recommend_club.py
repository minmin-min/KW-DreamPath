# ============================================
# ğŸ¤ SBERT ê¸°ë°˜ ë™ì•„ë¦¬ ì¶”ì²œ ì‹œìŠ¤í…œ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë²„ì „)
# ============================================

import os
import psycopg2
import numpy as np
from sentence_transformers import SentenceTransformer
from dotenv import load_dotenv

# ===== .env ë¶ˆëŸ¬ì˜¤ê¸° =====
load_dotenv()

# ===== ê¸°ë³¸ ì„¤ì • =====
PG_DSN = {
    "host": "localhost",
    "dbname": "KWchatbot",   # âš ï¸ DB ì´ë¦„ í™•ì¸
    "user": "postgres",
    "password": "6578"       # âš ï¸ ë³¸ì¸ ë¹„ë°€ë²ˆí˜¸ ë§ê²Œ
}


# ===== SBERT ëª¨ë¸ =====
MODEL_PATH = "jhgan/ko-sbert-sts"
model = SentenceTransformer(MODEL_PATH)


# ============================================
# ğŸ”¹ 1ï¸âƒ£ ë™ì•„ë¦¬ ì¹´í…Œê³ ë¦¬ì—ì„œ ìœ ì‚¬ ì²­í¬ ê²€ìƒ‰
# ============================================
def _fetch_similar_chunks(query_embedding, top_k=1):
    """
    'ë™ì•„ë¦¬' ì¹´í…Œê³ ë¦¬ì—ì„œ ì‚¬ìš©ì ì¿¼ë¦¬ì™€ ê°€ì¥ ìœ ì‚¬í•œ ì²­í¬ë¥¼ ì°¾ìŒ
    (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜)
    """
    conn = psycopg2.connect(**PG_DSN)
    cur = conn.cursor()

    # '<=>'ëŠ” PostgreSQLì˜ cosine distance ì—°ì‚°ì
    cur.execute(
        """
        SELECT 
            dc.doc_id,
            dc.chunk_id,
            dc.chunk_text,
            dc.category,
            (e.embedding <=> %s::vector) AS distance
        FROM embeddings e
        JOIN doc_chunks dc ON e.chunk_id = dc.chunk_id
        WHERE dc.category = 'ë™ì•„ë¦¬'
        ORDER BY e.embedding <=> %s::vector
        LIMIT %s;
        """,
        (query_embedding, query_embedding, top_k)
    )

    rows = cur.fetchall()
    cur.close()
    conn.close()
    return rows


# ============================================
# ğŸ”¹ 2ï¸âƒ£ ë™ì¼ ë™ì•„ë¦¬(doc_id)ì˜ ëª¨ë“  ì²­í¬ ê°€ì ¸ì˜¤ê¸°
# ============================================
def _fetch_all_chunks_by_doc(doc_id):
    """
    ê°™ì€ ë™ì•„ë¦¬(doc_id)ì˜ ëª¨ë“  ì²­í¬ë¥¼ chunk_index ìˆœìœ¼ë¡œ ë¶ˆëŸ¬ì˜´
    """
    conn = psycopg2.connect(**PG_DSN)
    cur = conn.cursor()

    cur.execute(
        """
        SELECT chunk_index, chunk_text
        FROM doc_chunks
        WHERE doc_id = %s
        ORDER BY chunk_index ASC;
        """,
        (doc_id,)
    )

    rows = cur.fetchall()
    cur.close()
    conn.close()
    return rows


# ============================================
# ğŸ”¹ 3ï¸âƒ£ ì¶”ì²œ í•¨ìˆ˜ (í•œ ë™ì•„ë¦¬ ë‹¨ìœ„)
# ============================================
def recommend_one_club(user_query):
    """
    ì‚¬ìš©ìì˜ ì…ë ¥ ë¬¸ì¥ì„ ê¸°ë°˜ìœ¼ë¡œ 'ë™ì•„ë¦¬' ì¹´í…Œê³ ë¦¬ ë‚´ì—ì„œ
    ê°€ì¥ ìœ ì‚¬í•œ 1ê°œ ë™ì•„ë¦¬(doc_id)ë¥¼ ì°¾ì•„ ëª¨ë“  ì²­í¬ë¥¼ ì¶œë ¥
    """
    # 1ï¸âƒ£ ì‚¬ìš©ì ì…ë ¥ ì„ë² ë”© ìƒì„±
    query_embedding = model.encode(user_query).tolist()

    # 2ï¸âƒ£ DB ê²€ìƒ‰
    rows = _fetch_similar_chunks(query_embedding, top_k=1)
    if not rows:
        return "â— ê´€ë ¨ ë™ì•„ë¦¬ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    # 3ï¸âƒ£ ê°€ì¥ ìœ ì‚¬í•œ ë™ì•„ë¦¬ì˜ doc_id ì¶”ì¶œ
    best_doc_id = rows[0][0]
    best_distance = float(rows[0][4])
    best_sim = round(1 - best_distance, 4)  # ìœ ì‚¬ë„ = 1 - ê±°ë¦¬

    # 4ï¸âƒ£ í•´ë‹¹ ë™ì•„ë¦¬ì˜ ëª¨ë“  ì²­í¬ ê°€ì ¸ì˜¤ê¸°
    chunks = _fetch_all_chunks_by_doc(best_doc_id)
    if not chunks:
        return f"â— doc_id={best_doc_id} ì— ëŒ€í•œ ì²­í¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    # 5ï¸âƒ£ ë™ì•„ë¦¬ í…ìŠ¤íŠ¸ í†µí•©
    full_text = "\n-----\n".join(
        [f"[{idx}] {txt}" for idx, txt in chunks]
    )

    # 6ï¸âƒ£ ë°˜í™˜ ê²°ê³¼ êµ¬ì„±
    result = {
        "ì¶”ì²œ_ë™ì•„ë¦¬_doc_id": best_doc_id,
        "ìœ ì‚¬ë„": best_sim,
        "í†µí•©_ë™ì•„ë¦¬_ì •ë³´": full_text
    }

    return result


# ============================================
# ğŸ”¹ ì‹¤í–‰ ì˜ˆì‹œ
# ============================================
if __name__ == "__main__":
    query = "ë°˜ë„ì²´ ê´€ë ¨ ë™ì•„ë¦¬ ì¶”ì²œí•´ì¤˜"
    print(f"\n[ì‚¬ìš©ì ì…ë ¥] {query}\n")

    rec = recommend_one_club(query)

    if isinstance(rec, str):
        print(rec)
    else:
        print(f"ğŸ¯ ì¶”ì²œ ë™ì•„ë¦¬ (doc_id={rec['ì¶”ì²œ_ë™ì•„ë¦¬_doc_id']}, ìœ ì‚¬ë„={rec['ìœ ì‚¬ë„']})\n")
        print(rec["í†µí•©_ë™ì•„ë¦¬_ì •ë³´"])
