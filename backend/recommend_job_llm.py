# ============================================
# ğŸ“š SBERT ê¸°ë°˜ ì·¨ì—… ì¶”ì²œ ì‹œìŠ¤í…œ + LLM ì„¤ëª… ìƒì„±
# ============================================

import os
import psycopg2
import numpy as np
from sentence_transformers import SentenceTransformer
from openai import OpenAI
from dotenv import load_dotenv

# ===== í™˜ê²½ë³€ìˆ˜ ë¡œë“œ =====
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ===== ê¸°ë³¸ ì„¤ì • =====
OPENAI_MODEL = "gpt-3.5-turbo"
PG_DSN = {
    "host": "localhost",
    "dbname": "kwchatbot",
    "user": "postgres",
    "password": "3864"
}
SIM_THRESHOLD = 0.25

# ===== SBERT ëª¨ë¸ =====
MODEL_PATH = "jhgan/ko-sbert-sts"
model = SentenceTransformer(MODEL_PATH)

# ===== OpenAI í´ë¼ì´ì–¸íŠ¸ =====
client = OpenAI(api_key=OPENAI_API_KEY)


# ============================================
# ğŸ”¹ 1ï¸âƒ£ ì·¨ì—… ì¹´í…Œê³ ë¦¬ì—ì„œ ìœ ì‚¬ ì²­í¬ ê²€ìƒ‰
# ============================================
def _fetch_similar_chunks(query_embedding, top_k=1):
    conn = psycopg2.connect(**PG_DSN)
    cur = conn.cursor()

    cur.execute(
        """
        SELECT 
            dc.doc_id,
            dc.chunk_id,
            dc.chunk_text,
            dc.category,
            1 - (e.embedding <#> %s::vector) AS similarity
        FROM embeddings e
        JOIN doc_chunks dc ON e.chunk_id = dc.chunk_id
        WHERE dc.category = 'ì·¨ì—…'
        ORDER BY e.embedding <#> %s::vector
        LIMIT %s;
        """,
        (query_embedding, query_embedding, top_k)
    )

    rows = cur.fetchall()
    cur.close()
    conn.close()
    return rows


# ============================================
# ğŸ”¹ 2ï¸âƒ£ ë™ì¼ doc_idì˜ ëª¨ë“  ì·¨ì—… ê´€ë ¨ ì²­í¬ ê°€ì ¸ì˜¤ê¸° (index=2 ì œì™¸)
# ============================================
def _fetch_all_chunks_by_doc(doc_id):
    conn = psycopg2.connect(**PG_DSN)
    cur = conn.cursor()

    cur.execute(
        """
        SELECT chunk_index, chunk_text
        FROM doc_chunks
        WHERE doc_id = %s
          AND chunk_index != 2
        ORDER BY chunk_index ASC;
        """,
        (doc_id,)
    )

    rows = cur.fetchall()
    cur.close()
    conn.close()
    return rows


# ============================================
# ğŸ”¹ 3ï¸âƒ£ ì¶”ì²œ í•¨ìˆ˜ + LLM ì„¤ëª… ìƒì„±
# ============================================
def recommend_and_describe_job(user_query):
    # 1ï¸âƒ£ ì‚¬ìš©ì ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
    query_embedding = model.encode(user_query).tolist()

    # 2ï¸âƒ£ ìœ ì‚¬ ì²­í¬ ê²€ìƒ‰
    rows = _fetch_similar_chunks(query_embedding, top_k=1)
    if not rows:
        return "â— ê´€ë ¨ ì·¨ì—… ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    # 3ï¸âƒ£ ê°€ì¥ ìœ ì‚¬í•œ ì·¨ì—… ì •ë³´(doc_id) ì„ íƒ
    best_doc_id = rows[0][0]
    best_sim = round(float(rows[0][4]), 4)

    # 4ï¸âƒ£ í•´ë‹¹ ì·¨ì—… ì •ë³´ì˜ ëª¨ë“  ì²­í¬ ê°€ì ¸ì˜¤ê¸° (index=2 ì œì™¸)
    chunks = _fetch_all_chunks_by_doc(best_doc_id)
    if not chunks:
        return f"â— doc_id={best_doc_id} ì— ëŒ€í•œ ì·¨ì—… ì²­í¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    # 5ï¸âƒ£ í…ìŠ¤íŠ¸ í†µí•©
    full_text = "\n-----\n".join(
        [f"[{idx}] {txt}" for idx, txt in chunks]
    )

    # 6ï¸âƒ£ LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    system_prompt = """
    ë‹¹ì‹ ì€ ê´‘ìš´ëŒ€í•™êµ KW Chatbotì˜ ì·¨ì—…/ì§„ë¡œ ì¶”ì²œ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
    ì•„ë˜ CONTEXTëŠ” íŠ¹ì • ì·¨ì—… ì •ë³´(ì§„ë¡œ ë¡œë“œë§µ, ì¤€ë¹„ ë°©ë²•, ê´€ë ¨ ê°•ì˜/ë™ì•„ë¦¬ ë“±)ì— ëŒ€í•œ ë‚´ìš©ì…ë‹ˆë‹¤.
    ì´ ì •ë³´ë¥¼ ìš”ì•½í•˜ê³ ,
    ì‚¬ìš©ìì˜ ê´€ì‹¬ ì§ë¬´ì™€ ìƒí™©ì— ë§ê²Œ ì–´ë–¤ ì‹ìœ¼ë¡œ í™œìš©í•˜ë©´ ì¢‹ì„ì§€
    í•™ìƒ ëˆˆë†’ì´ì— ë§ì¶° êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
    """

    user_prompt = f"""
    [ì‚¬ìš©ì ì§ˆë¬¸]
    {user_query}

    [ì·¨ì—… ì •ë³´]
    {full_text}
    """

    # 7ï¸âƒ£ GPT í˜¸ì¶œ
    try:
        resp = client.chat.completions.create(
            model=OPENAI_MODEL,
            temperature=0.5,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
        )
        description = resp.choices[0].message.content
    except Exception as e:
        description = f"â— GPT ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

    # 8ï¸âƒ£ ê²°ê³¼ ë°˜í™˜
    result = {
        "ì¶”ì²œ_ì·¨ì—…_doc_id": best_doc_id,
        "ìœ ì‚¬ë„": best_sim,
        "ì·¨ì—…_ë‚´ìš©": full_text,
        "LLM_ì„¤ëª…": description
    }

    return result


# ============================================
# ğŸ”¹ ì‹¤í–‰ ì˜ˆì‹œ
# ============================================
if __name__ == "__main__":
    query = "ë°±ì—”ë“œ ê°œë°œìë¡œ ì·¨ì—… ì¤€ë¹„ë¥¼ í•˜ë ¤ë©´ í•™êµì—ì„œ ë­˜ í•´ì•¼ í• ê¹Œìš”?"
    print(f"\n[ì‚¬ìš©ì ì…ë ¥] {query}\n")

    rec = recommend_and_describe_job(query)

    if isinstance(rec, str):
        print(rec)
    else:
        print(f"ğŸ¯ ì¶”ì²œ ì·¨ì—… ì •ë³´ (doc_id={rec['ì¶”ì²œ_ì·¨ì—…_doc_id']}, ìœ ì‚¬ë„={rec['ìœ ì‚¬ë„']})\n")
        print("ğŸ“˜ ì·¨ì—… ì •ë³´:\n", rec["ì·¨ì—…_ë‚´ìš©"])
        print("\nğŸ’¬ LLM ì„¤ëª…:\n", rec["LLM_ì„¤ëª…"])
